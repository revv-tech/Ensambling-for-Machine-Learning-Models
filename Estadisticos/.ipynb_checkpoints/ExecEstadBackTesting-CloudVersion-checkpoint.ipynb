{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75a27518",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "import pickle\n",
    "import math\n",
    "import time\n",
    "import re\n",
    "import glob\n",
    "from sktime.forecasting.ets import AutoETS\n",
    "from pmdarima.arima import auto_arima\n",
    "from sktime.forecasting.theta import ThetaForecaster\n",
    "from joblib import Parallel, delayed  # paralle process\n",
    "# Manage Dir File List\n",
    "import re\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5aa0f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''    \n",
    "#######################################################################################\n",
    "#FUNCTION TO SPLIT TRAINING, VALIDATION AND TESTING IN INPUT AND OUTPUT FOR EACH DATASET\n",
    "########################################################################################\n",
    "\n",
    "#Arguments\n",
    "## data= list with numpy dataset of training, validation and testing\n",
    "## h = horizon output\n",
    "\n",
    "\n",
    "#Outputs\n",
    "## dat=List with input and output for training, validation and testing\n",
    "'''\n",
    "\n",
    "def dataSplitXy(data, h):\n",
    "    \n",
    "    # split X, y in train\n",
    "    x_trainCopy=data[0]\n",
    "    x_train=x_trainCopy[:,:-h]\n",
    "    y_train=x_trainCopy[:,-h:]\n",
    "\n",
    "    x_train=x_train.reshape((x_train.shape[0], x_train.shape[1],1))\n",
    "    y_train=y_train.reshape((y_train.shape[0], y_train.shape[1], 1))\n",
    "\n",
    "    # split X, y in val\n",
    "    x_valCopy=data[1]\n",
    "    x_val=x_valCopy[:,:-h]\n",
    "    y_val=x_valCopy[:,-h:]\n",
    "\n",
    "    x_val=x_val.reshape((x_val.shape[0], x_val.shape[1],1))\n",
    "    y_val=y_val.reshape((y_val.shape[0], y_val.shape[1],1))\n",
    "\n",
    "    \n",
    "     # split X, y in test\n",
    "    x_testCopy=data[2]\n",
    "    x_test=x_testCopy[:,:-h]\n",
    "    y_test=x_testCopy[:,-h:]\n",
    "\n",
    "    x_test=x_test.reshape((x_test.shape[0], x_test.shape[1],1))\n",
    "    y_test=y_test.reshape((y_test.shape[0], y_test.shape[1],1))\n",
    "    \n",
    "    dat=[x_train, y_train, x_val, y_val, x_test, y_test]\n",
    "    \n",
    "    return dat\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "##########################################################################\n",
    "#FUNCTION FOR DATASET PREPARATION TO BE USED WITH A MACHINE LEARNING MODEL \n",
    "#########################################################################\n",
    "\n",
    "#Arguments\n",
    "##data= time serie, with panda or numpy\n",
    "## n_in = input window\n",
    "## n_out= forecast horizon\n",
    "\n",
    "#Outputs\n",
    "##tr=dataset for training with machine learning approach\n",
    "##te=dataset for testing with machine learning approach\n",
    "'''\n",
    "\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1):\n",
    "    df = pd.DataFrame(data)\n",
    "    cols = list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "    # forecast seque...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................nce (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "    # put it all together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    \n",
    "    # drop rows with NaN values\n",
    "    agg.dropna(inplace=True)\n",
    "    \n",
    "    # Put names to the columns\n",
    "    ## names to input columns\n",
    "    a1=np.arange(n_in)\n",
    "    a1 = a1.astype(str) \n",
    "    a2=np.repeat('I',n_in)\n",
    "    a=np.core.defchararray.add(a2, a1)\n",
    "    \n",
    "    ## names to output columns\n",
    "    b1=np.arange(n_out)\n",
    "    b1 = b1.astype(str) \n",
    "    b2=np.repeat('O',n_out)\n",
    "    b=np.core.defchararray.add(b2, b1)\n",
    "    \n",
    "    ## change columna names by new names\n",
    "    agg.columns=np.append(a,b)\n",
    "    \n",
    "    #Index for train and test selection\n",
    "    last=18-n_out+1\n",
    "    prelast=last+n_out-1\n",
    "    \n",
    "    # Division in train and test\n",
    "    te=agg.iloc[-last:,:]\n",
    "    tr=agg.iloc[:-prelast,:]\n",
    "    \n",
    "    return tr,te\n",
    "\n",
    "\n",
    "def metrics(pre, real):\n",
    "    \n",
    "    # sMAPE\n",
    "    sMAPE=np.sum(np.abs(pre-real))/np.sum((pre+real))\n",
    "    \n",
    "    #MAE\n",
    "    \n",
    "    MAE=np.mean(np.abs(pre-real)/len(real))\n",
    "        \n",
    "    #MAPE\n",
    "    MAPE=np.mean(np.abs((real-pre)/real))\n",
    "    \n",
    "    return sMAPE, MAE, MAPE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68ad8bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "# Auto ETS\n",
    "def ets(tr):\n",
    "    modAutoETS = AutoETS(auto=True, initialization_method='heuristic', error='add', trend ='add', damped_trend=True,seasonal='add' ,sp=12)\n",
    "    modAutoETS.fit(tr)\n",
    "    \n",
    "    return modAutoETS\n",
    "\n",
    "'''\n",
    "# Auto ETS\n",
    "def arima(tr):\n",
    "    modAutoARIMA = AutoARIMA(sp=12,d=1, max_p=5, max_q=5, max_P=5, max_Q=5,start_p=0, start_q=0 ,start_P=0,  start_Q=0,seasonal=True, stepwise=True, suppress_warnings=False, random_state=15)\n",
    "    modAutoARIMA.fit(tr)\n",
    "    \n",
    "    return modAutoARIMA\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# Auto ETS\n",
    "def arima2(tr):\n",
    "    modAutoARIMA = auto_arima(tr, seasonal=True, m=12, maxiter=25)    \n",
    "    return modAutoARIMA\n",
    "\n",
    "# Auto Theta\n",
    "def theta(tr):\n",
    "    modTheta = ThetaForecaster(sp=12)\n",
    "    modTheta.fit(tr)\n",
    "    return modTheta\n",
    "\n",
    "\n",
    "'''\n",
    "############################################################################\n",
    "#FUNCTION TO GET METRICS AND PREDICTIONS OF ETS, ARIMA, THETA\n",
    "#############################################################################\n",
    "\n",
    "#Arguments\n",
    "## serie= serie pandas, one time serie\n",
    "##funciones = List with the functions to execute statistical models\n",
    "##horizon= List with the output sizes\n",
    "##rep=int of number of repetitions\n",
    "## pathSave=path to save results\n",
    "\n",
    "#Outputs\n",
    "##results = numpy array with id of serie, idsd of model, output,  sMAPE  MAE, MAPE\n",
    "##predictionsList = list with predictions for each optimal model.\n",
    "\n",
    "#####################################################################\n",
    "'''\n",
    "\n",
    "\n",
    "def estadisModelsBackTesting(serie, funciones, horizon, rep, pathSave):\n",
    "    print(\"Processing \" + str(int(serie[0])))\n",
    "    # list to save results\n",
    "    results=[]\n",
    "    predictionsList=[]\n",
    "    realList=[]\n",
    "    # Loop over each horizon\n",
    "    for h in horizon:\n",
    "        print('making horizon', h)\n",
    "        # horizon window\n",
    "        fh = np.arange(1, h+1) \n",
    "        fh2=int(h)\n",
    "        # index to finish training and begin testing\n",
    "        finTr=int(serie.shape[0]-h)\n",
    "        for i in range(rep):\n",
    "            print('making repetetition:', i, 'from horizon:', h)\n",
    "            # Divide serie in training and test\n",
    "            tr=serie[1:finTr]\n",
    "            te=serie[finTr:(finTr+h)]\n",
    "            tr=tr.values\n",
    "            te=te.values\n",
    "\n",
    "            # execute each function\n",
    "            for f in funciones:\n",
    "                mod=f(tr)\n",
    "                # make prediction\n",
    "                \n",
    "                if f==arima2:\n",
    "                    pre=mod.predict(fh2)\n",
    "                    \n",
    "                else:\n",
    "                    pre=mod.predict(fh)\n",
    "                    \n",
    "                # transpose prediction\n",
    "                preF=np.transpose(pre)\n",
    "                #  save prediction\n",
    "                predictionsList.append(preF)\n",
    "                \n",
    "                realList.append(te.reshape(1,-1))\n",
    "        \n",
    "                # metrics\n",
    "                results.append(metrics(preF, te.reshape(1,-1)))\n",
    "            # update count for backtesting\n",
    "            finTr=int(finTr-h)          \n",
    "   \n",
    "    # Final format of the metrics file  #######################################REVISAR DESDE AQUI\n",
    "    results=pd.DataFrame(results) \n",
    "    results.insert(0, \"id_serie\", np.repeat(int(serie[0]),len(results)), True)\n",
    "    results.insert(1,\"rep\", np.tile(np.repeat(np.arange(rep),len(funciones)),len(horizon)), True)\n",
    "    results.insert(2, \"id_model\",np.tile(['ets', 'theta', 'arima'], (len(horizon)*rep)) , True) #####\n",
    "    results.insert(3, \"output\",np.repeat(horizon,len(funciones)*rep), True)\n",
    "    results.columns=['id_serie', \"rep\", 'id_model', 'output', 'sMAPE', 'MAE', 'MAPE']\n",
    "        \n",
    "    # Agregar carpetas en el path save met / pred / real\n",
    "    results.to_csv(pathSave+'met/'+'metricasEstad_'+str(int(serie[0])) +'.csv')\n",
    "    np.save(pathSave+'pred/'+'predictionsListEstad'+str(int(serie[0]))+'.npy',  predictionsList, allow_pickle=True) \n",
    "    np.save(pathSave+'real/'+'realListEstad'+str(int(serie[0]))+'.npy',  predictionsList, allow_pickle=True) \n",
    "   \n",
    "    return results,  predictionsList\n",
    "    #return pre, preF,te\n",
    "\n",
    "\n",
    "'''\n",
    "############################################################################\n",
    "#FUNCTION TO PARALLEL ETS, ARIMA, THETA FOR EACH TIME SERIE\n",
    "#############################################################################\n",
    "\n",
    "#Arguments\n",
    "## dataset= pandas dataset with the time series in rows\n",
    "## rep= int of number of repetitions\n",
    "##ids = numpy vector with ids of the time series that will be used\n",
    "## pathSave= path where the results and predictions will be save itt\n",
    "## core = int, number of cores to be used\n",
    "\n",
    "#Outputs\n",
    "##results = numpy array with id of serie, ids of model, output,  sMAPE  MAE, MAPE\n",
    "##predictionsList = list with predictions for each optimal model.\n",
    "\n",
    "#####################################################################\n",
    "'''\n",
    "    \n",
    "def  estadisModelsBackTestingParallel(dataset, rep, ids, pathSave, core):\n",
    "    parametros=[]\n",
    "    for k in range(ids.shape[0]):\n",
    "        serie=dataset.loc[dataset['Unnamed: 0']==int(ids[k])]\n",
    "        serie=serie.iloc[0]\n",
    "        #serie.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "        serie.dropna(inplace=True)\n",
    "        parametros.append([serie, funciones,horizon, rep, pathSave])\n",
    "        \n",
    "    \n",
    "    reTot=Parallel(n_jobs=core)(delayed(estadisModelsBackTesting)(serie, funciones, horizon,rep, pathSave) for serie, funciones, horizon, rep, pathSave in parametros)\n",
    "    # generating empty arrays to append results\n",
    "    metrics=np.empty((0,reTot[0][0].shape[1]))\n",
    "    lPred=[]\n",
    "\n",
    "    # append results \n",
    "    for k in range(len(reTot)):\n",
    "        # append in arrays\n",
    "        metrics=np.append(metrics, reTot[k][0], axis=0)\n",
    "        lPred=lPred+reTot[k][1]   \n",
    "\n",
    "    #save datasets\n",
    "    metrics=pd.DataFrame(metrics)\n",
    "    metrics.columns=['id_serie', \"rep\", 'id_model', 'output', 'sMAPE', 'MAE', 'MAPE']\n",
    "    metrics.to_csv(pathSave+'metricasEstad.csv')\n",
    "    np.save(pathSave+'predictionsListEstad.npy', lPred, allow_pickle=True) \n",
    "   \n",
    "        \n",
    "    return metrics, lPred\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "############################################################################\n",
    "#FUNCTION TO EXECUTE ETS, ARIMA, THETA FOR EACH TIME SERIE\n",
    "#############################################################################\n",
    "\n",
    "#Arguments\n",
    "## dataset= pandas dataset with the time series in rows\n",
    "## ids = numpy vector with ids of the time series that will be used\n",
    "##funciones = List with the functions to execute statistical models\n",
    "##horizon= List with the output sizes\n",
    "##rep=int of number of repetitions\n",
    "## pathSave=path to save results\n",
    "\n",
    "\n",
    "#Outputs\n",
    "##results = numpy array with id of serie, ids of model, output,  sMAPE  MAE, MAPE\n",
    "##predictionsList = list with predictions for each optimal model.\n",
    "\n",
    "#####################################################################\n",
    "'''\n",
    "\n",
    "def estadisModelsBackTestingAll(dataset, ids, funciones, horizon, rep, pathSave):\n",
    "    for k in range(ids.shape[0]):\n",
    "        print('generating serie', k)\n",
    "        serie=dataset.loc[dataset['Unnamed: 0']==int(ids[k])]\n",
    "        serie=serie.iloc[0]\n",
    "        serie.dropna(inplace=True)\n",
    "        results, predictionsList=estadisModelsBackTesting(serie, funciones, horizon, rep, pathSave)\n",
    "\n",
    "def manageDirList(dirList):\n",
    "    if dirList == []:\n",
    "        return []\n",
    "    else:\n",
    "        n = dirList[0].split(\"_\")[1]\n",
    "        n = n.split(\".\")[0]\n",
    "        return [int(n)] + manageDirList(dirList[1:])\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16f5ed7e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "##################################### Backtesting FMI ###########################################\n",
    "# load complete dataset\n",
    "dataset=read_csv('C:/Users/TimeSeriesUser/Desktop/MetaLearning/Scripts/Estadisticos/teOrg.csv')\n",
    "horizon=[3, 12]\n",
    "funciones=[ets, theta, arima2]\n",
    "rep=3\n",
    "core=3\n",
    "pathSave='C:/Users/TimeSeriesUser/Desktop/MetaLearning/Scripts/Estadisticos/Results/'\n",
    "# ids\n",
    "ids=np.array(dataset.iloc[:,0])\n",
    "#Get files from the dir\n",
    "onlyfiles = [f for f in listdir('C:/Users/TimeSeriesUser/Desktop/MetaLearning/Scripts/Estadisticos/Results/met') if isfile(join('C:/Users/TimeSeriesUser/Desktop/MetaLearning/Scripts/Estadisticos/Results/met', f))]\n",
    "alreadyDid = np.array(manageDirList(onlyfiles))\n",
    "df = pd.DataFrame(alreadyDid)\n",
    "df.to_csv('C:/Users/TimeSeriesUser/Desktop/MetaLearning/Scripts/Estadisticos/file.csv', index = False, header=True)\n",
    "# Get rid of ts ids in dir results\n",
    "ids = np.setdiff1d(ids, alreadyDid)\n",
    "\n",
    "#metrics, lPred, =estadisModelsBackTestingParallel(dataset, rep, ids, pathSave, core)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae6e977",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd58b194",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
